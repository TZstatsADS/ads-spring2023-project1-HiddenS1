{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Functions included in project1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# remove stopwords from texts\n",
                "def remove_stopwords(texts):\n",
                "    return [[word for word in simple_preprocess(str(doc)) \n",
                "             if word not in stop_words] for doc in texts]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# generate the dominant topic and its percentage\n",
                "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
                "    sent_topics_df = pd.DataFrame()\n",
                "    for i, row_list in enumerate(ldamodel[corpus]):\n",
                "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
                "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
                "        for j, (topic_num, prop_topic) in enumerate(row):\n",
                "            if j == 0:  \n",
                "                wp = ldamodel.show_topic(topic_num)\n",
                "                topic_keywords = \", \".join([word for word, prop in wp])\n",
                "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
                "            else:\n",
                "                break\n",
                "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
                "    contents = pd.Series(texts)\n",
                "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
                "    return(sent_topics_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# get the word frequency in a specific school\n",
                "def findcount(word,sch,ds):\n",
                "    ds = ds.loc[ds.school==sch]\n",
                "    sum = 0\n",
                "    for texts in ds.tokenized_txt:\n",
                "        sum += eval(texts).count(word)\n",
                "    return(sum/len(ds))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# return a dataframe with the top 2 word frequency in before and top 3 word frequency in after\n",
                "def topschools(word):\n",
                "    countsbef = []\n",
                "    for sch in schoolsbef:\n",
                "        countsbef.append(findcount(word,sch,bef))\n",
                "    ds1 = pd.DataFrame({'counts': countsbef, 'sch': schoolsbef})\n",
                "    ds1 = ds1.sort_values('counts')[1:]\n",
                "    countsaft = []\n",
                "    for sch in schoolsaft:\n",
                "        countsaft.append(findcount(word,sch,aft))\n",
                "    ds2 = pd.DataFrame({'counts': countsaft, 'sch': schoolsaft})\n",
                "    ds2 = ds2.sort_values('counts')[7:]\n",
                "    index = ['bef','aft']\n",
                "    cols = ds1.sch.tolist()+ds2.sch.tolist()\n",
                "    theds = pd.DataFrame(0,columns=cols,index=index)\n",
                "    for col in ds1.sch:\n",
                "        theds.loc['bef',col] = float(ds1.loc[ds1.sch==col,'counts'])\n",
                "    for col in ds2.sch:\n",
                "        theds.loc['aft',col] = float(ds2.loc[ds2.sch==col,'counts'])\n",
                "    return(theds)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# generate a list of bools of if the word is in the sentence\n",
                "def iswoman(ds):\n",
                "    isin = []\n",
                "    for sentence in ds.sentence_lowered:\n",
                "        if re.search(r'\\bwoman\\b',sentence):\n",
                "            isin.append(True)\n",
                "        else:\n",
                "            isin.append(False)\n",
                "    return isin\n",
                "def isman(ds):\n",
                "    isin = []\n",
                "    for sentence in ds.sentence_lowered:\n",
                "        if re.search(r'\\bman\\b',sentence):\n",
                "            isin.append(True)\n",
                "        else:\n",
                "            isin.append(False)\n",
                "    return isin\n",
                "def isfe(ds):\n",
                "    isin = []\n",
                "    for sentence in ds.sentence_lowered:\n",
                "        if re.search(r'\\bfemale\\b',sentence):\n",
                "            isin.append(True)\n",
                "        else:\n",
                "            isin.append(False)\n",
                "    return isin\n",
                "def isma(ds):\n",
                "    isin = []\n",
                "    for sentence in ds.sentence_lowered:\n",
                "        if re.search(r'\\bmale\\b',sentence):\n",
                "            isin.append(True)\n",
                "        else:\n",
                "            isin.append(False)\n",
                "    return isin"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# generate n most common words and their counts in sentences that mention the given word\n",
                "def wordcount(ds,word,n,stop=stop_word):\n",
                "    if word=='man':\n",
                "        ds = ds.loc[isman(ds)]\n",
                "    elif word=='woman':\n",
                "        ds = ds.loc[iswoman(ds)]\n",
                "    elif word=='female':\n",
                "        ds = ds.loc[isfe(ds)]\n",
                "    else:\n",
                "        ds = ds.loc[isma(ds)]\n",
                "    fetokens = [eval(tokens) for tokens in ds['tokenized_txt']]\n",
                "    fetoken = remove_stopwords2(fetokens, stop_word)\n",
                "    fetoken = [t for tokens in fetoken for t in tokens]\n",
                "    counts_fe = Counter(fetoken)\n",
                "    return(counts_fe.most_common(n))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# judge if a sentence is positive\n",
                "def sentiment_scores(sentence):\n",
                "    sid_obj = SentimentIntensityAnalyzer()\n",
                "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
                "    if sentiment_dict['compound'] >= 0.05 :\n",
                "        return(\"Positive\")\n",
                " \n",
                "    elif sentiment_dict['compound'] <= - 0.05 :\n",
                "        return(\"Negative\")\n",
                " \n",
                "    else :\n",
                "        return(\"Neutral\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# generate a pie chart including the positive, negative and neutral proportion in a given dataset\n",
                "def senti(df):      \n",
                "    corpus = ''\n",
                "    numPostives = 0\n",
                "    numNegatives = 0\n",
                "    numNeutrals = 0\n",
                "    \n",
                "    for mem in df['sentence_lowered']:\n",
                "        corpus += mem\n",
                "    \n",
                "    for i in range (len(df)):\n",
                "        sent = (sentiment_scores(df['sentence_lowered'].iloc[i]))\n",
                "        if sent == \"Positive\":\n",
                "            numPostives += 1\n",
                "        elif sent == \"Negative\":\n",
                "            numNegatives += 1\n",
                "        else:\n",
                "            numNeutrals += 1\n",
                "    \n",
                "    if len(df)<100000:\n",
                "        thetime = 'early'\n",
                "    else:\n",
                "        thetime = 'modern'\n",
                "\n",
                "    plt.figure(figsize = (7, 7))\n",
                "    plt.pie([numPostives, numNegatives, numNeutrals], labels = ['positives', 'negatives', 'neutrals'], autopct='%1.2f%%', colors = ['#ff9999','#66b3ff','#ffcc99'])\n",
                "    plt.title('Sentiment Analysis for '+thetime+ ' Philosopher')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
        },
        "vscode": {
            "interpreter": {
                "hash": "3440fa40ac2c39878b83ee7a6e81824601a62799733fc81e385c4ef9c8700d77"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
